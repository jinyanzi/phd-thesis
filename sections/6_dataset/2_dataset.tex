\section{Dataset}
To the best of our knowledge, there exists no public traffic surveillance video dataset containing complex real world interactions and illumination variations. 
Existing vision datasets are either not applicable to our scenario with different viewpoint (driver's view) \cite{sivaraman2010general} 
or contain short clips with limited adversarial conditions, scale changes, and illumination variations \cite{manen2014appearances,wu2015object}. %wang2009unsupervised
Even in the largest dataset collected \cite{wu2015object}, only 15 out of 98 videos exceeds 1000 frames (33 seconds).%, and only a single video containing 4,000 frames. 

We collected 11 representative surveillance videos across our state, from the local department of transportation, and annotated these using VATIC \cite{springerlink:10.1007/s11263-012-0564-1}. Each object has its location and extent annotated on every frame, which is used as our ground truth. The average length of each video is five minutes (around 9000 frames), sufficient to cover several traffic signal cycles with real-world vehicle interactions and movement patterns. We divide the videos into two groups: simple low resolution (lowRes) and complex high resolution (highRes). \ref{fig:screenshots} shows screen shots from this dataset, and \ref{table:videos} gives an overview of our dataset, where the rightmost four columns indicate the number of videos reflecting various challenging aspects: occlusion, shadows, distortion and pedestrians.
%Although night videos also have high resolutions, we put then in a separate group due to the special illumination conditions.
%The dataset is currently available on [LINK].
\input{tables/dataset.tex}
\input{img/dataset.tex}